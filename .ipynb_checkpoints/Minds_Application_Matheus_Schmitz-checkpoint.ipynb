{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "human-bicycle",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Py Data Stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Classifiers\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Sklearn Auxilarty Functions\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Auxilary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-buddy",
   "metadata": {},
   "source": [
    "## 1. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', 'word_freq_over',\n",
    "             'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will',\n",
    "             'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free', 'word_freq_business', 'word_freq_email',\n",
    "             'word_freq_you', 'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp',\n",
    "             'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857',\n",
    "             'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm',\n",
    "             'word_freq_direct', 'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re', 'word_freq_edu',\n",
    "             'word_freq_table', 'word_freq_conference', 'char_freq_;',  'char_freq_(', 'char_freq_[', 'char_freq_!', 'char_freq_$',\n",
    "             'char_freq_#', 'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'LABEL']\n",
    "len(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spambase.data', header=None, names=col_names)\n",
    "print(f'df.shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any missing values and if all data types were properly loaded\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-steering",
   "metadata": {},
   "source": [
    "### 1.1. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test= train_test_split(df, test_size=0.2, stratify=df.iloc[:,-1])\n",
    "print(f'df_train.shape: {df_train.shape}')\n",
    "print(f'df_test.shape: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-playing",
   "metadata": {},
   "source": [
    "### 1.2. Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-quantity",
   "metadata": {},
   "source": [
    "Considering only the training data so as to leave testing data untouched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of datapoint\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of values using a boxplot\n",
    "fix, ax = plt.subplots(figsize=(15,15))\n",
    "df_train.boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-tamil",
   "metadata": {},
   "source": [
    "The skewness in this boxplot indicated the need to implement a MinMaxScaler during the model training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "fig, ax = plt.subplots(figsize=(40,40))\n",
    "g = sns.heatmap(df_train.corr(), vmin=-1, vmax=1, cmap='coolwarm_r', square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient of Variation\n",
    "var_mean = df_train.mean(axis=0)\n",
    "var_std = df_train.std(axis=0)\n",
    "CV = var_std/var_mean\n",
    "CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the features with the highest CV\n",
    "num_picks = int(np.floor(np.sqrt(df.shape[1])))\n",
    "print(f'Number of features chosen: {num_picks}')\n",
    "chosen_features = CV.sort_values(ascending=False).head(num_picks).index\n",
    "chosen_features = [i for i in chosen_features]\n",
    "print(f'List of features chosen: {chosen_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplots using target variable as hue\n",
    "g = sns.pairplot(data=df_train[chosen_features], plot_kws=dict(hue=df_train.iloc[:,-1] , palette='coolwarm'), diag_kws=dict(color='black'))\n",
    "g.add_legend(title=\"Target Variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "g = sns.boxplot(data=df_train[chosen_features], orient='h')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-advocate",
   "metadata": {},
   "source": [
    "## 2. Building the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-microwave",
   "metadata": {},
   "source": [
    "### 2.1 Defining Grid Searches to Optimize the Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-pledge",
   "metadata": {},
   "source": [
    "#### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "august-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to standardize then run the classifier\n",
    "svc =  Pipeline([(\"standardize\", StandardScaler()),\n",
    "                 (\"svc\", SVC(kernel=\"rbf\", decision_function_shape='ovr'))])\n",
    "\n",
    "# Grid with parameters to be tested via CV\n",
    "svc_param_grid_ = {'svc__C': np.logspace(-3, 3, 5),\n",
    "                   'svc__gamma': np.logspace(-3, 3, 5)}\n",
    "\n",
    "# Instantiate GridSearchCV using accuracy as the scorer\n",
    "svc_gridCV = GridSearchCV(svc, svc_param_grid_, cv=5, n_jobs=-1, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-victory",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "brilliant-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to standardize then run the classifier\n",
    "rfc = Pipeline([(\"standardize\", StandardScaler()),\n",
    "                 (\"rfc\", RandomForestClassifier(n_estimators=100, criterion='gini', n_jobs=-1))]) \n",
    "\n",
    "# Grid with parameters to be tested via CV\n",
    "rfc_param_grid_ = {'rfc__min_samples_split': [2,3],\n",
    "                   'rfc__min_samples_leaf': [1,2,3]}\n",
    "\n",
    "# Instantiate GridSearchCV using accuracy as the scorer\n",
    "rfc_gridCV = GridSearchCV(rfc, rfc_param_grid_, cv=5, n_jobs=-1, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-music",
   "metadata": {},
   "source": [
    "#### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "verbal-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = Pipeline([(\"standardize\", StandardScaler()),\n",
    "                (\"knn\", KNeighborsClassifier(metric='minkowski', leaf_size=30, weights='distance', n_jobs=-1))]) \n",
    "\n",
    "# Grid with parameters to be tested via CV\n",
    "knn_param_grid_ = {'knn__n_neighbors': [3,5,7,9]}\n",
    "\n",
    "# Instantiate GridSearchCV using accuracy as the scorer\n",
    "knn_gridCV = GridSearchCV(knn, knn_param_grid_, cv=5, n_jobs=-1, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-prompt",
   "metadata": {},
   "source": [
    "#### Gaussian Process Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ruled-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpc = Pipeline([(\"standardize\", StandardScaler()),\n",
    "                (\"gpc\", GaussianProcessClassifier(optimizer='fmin_l_bfgs_b', max_iter_predict=100, n_jobs=-1))]) \n",
    "\n",
    "# Grid with parameters to be tested via CV\n",
    "gpc_param_grid_ = {'gpc__n_restarts_optimizer': [0,5,10]}\n",
    "\n",
    "# Instantiate GridSearchCV using accuracy as the scorer\n",
    "gpc_gridCV = GridSearchCV(gpc, gpc_param_grid_, cv=5, n_jobs=-1, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-executive",
   "metadata": {},
   "source": [
    "#### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "headed-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = Pipeline([(\"standardize\", StandardScaler()),\n",
    "                (\"lda\", LinearDiscriminantAnalysis(solver='svd'))]) \n",
    "\n",
    "# Grid with parameters to be tested via CV\n",
    "lda_param_grid_ = {'lda__tol': [1.0e-2, 1.0e-4, 1.0e-6]}\n",
    "\n",
    "# Instantiate GridSearchCV using accuracy as the scorer\n",
    "lda_gridCV = GridSearchCV(lda, lda_param_grid_, cv=5, n_jobs=-1, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-retention",
   "metadata": {},
   "source": [
    "### 2.2 Finding Optimal Hyperparameter with Grid Search & K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "scenic-venice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Fold: 1\n",
      "Working on Fold: 2\n",
      "Working on Fold: 3\n",
      "Working on Fold: 4\n",
      "Working on Fold: 5\n",
      "\n",
      "--- GridSearch Best Parameters ---\n",
      "Mean SVC C Parameter: 1000.0\n",
      "Mean SVC gamma Parameter: 0.001\n",
      "Mean RFC min_samples_split Parameter: 2.2\n",
      "Mean RFC min_samples_leaf Parameter: 1.0\n",
      "Mean KNN N Parameter: 2.2\n",
      "Mean GPA n_restarts_optimizer Parameter: 0.0\n",
      "Mean LDA tol Parameter: 0.01\n",
      "\n",
      "--- K-Fold Cross-Validation Results ---\n",
      "SVC Error | Training : 0.03329469338255566\n",
      "RFC Error | Training : 0.0002801126074668536\n",
      "KNN Error | Training : 0.00016806778953968316\n",
      "GPC Error | Training : 0.01059442754648281\n",
      "LDA Error | Training : 0.09220863331581039\n",
      "\n",
      "SVC Error | Validation : 0.0605978260869565\n",
      "RFC Error | Validation : 0.044836956521739135\n",
      "KNN Error | Validation : 0.08804347826086956\n",
      "GPC Error | Validation : 0.0798913043478261\n",
      "LDA Error | Validation : 0.09429347826086956\n",
      "\n",
      "Wall time: 12min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Instantiate SMOTE\n",
    "smote = SMOTE(n_jobs=-1)\n",
    "\n",
    "# KFold\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "kfold_intermediate_results = pd.DataFrame()\n",
    "for fold_num, (idx_train, idx_valid) in enumerate(kf.split(df_train), 1):\n",
    "\n",
    "    # Print current label and fold\n",
    "    print(f'Working on Fold: {fold_num}')\n",
    "\n",
    "    # Select all folds to be smoted except for the validation fold\n",
    "    x_train, y_train = smote.fit_sample(df_train.iloc[idx_train,:-1], df_train.iloc[idx_train,-1])\n",
    "    x_valid = df_train.iloc[idx_valid,:-1] \n",
    "    y_valid = df_train.iloc[idx_valid,-1] \n",
    "\n",
    "    # Fit using grid search to find the best params\n",
    "    svc_gridCV.fit(x_train, y_train)\n",
    "    rfc_gridCV.fit(x_train, y_train)\n",
    "    knn_gridCV.fit(x_train, y_train)\n",
    "    gpc_gridCV.fit(x_train, y_train)\n",
    "    lda_gridCV.fit(x_train, y_train)\n",
    "\n",
    "    # Predict on the train and validation folds to calculate metrics\n",
    "    pred_svc_train = svc_gridCV.predict(x_train)   \n",
    "    pred_svc_valid = svc_gridCV.predict(x_valid)\n",
    "    pred_rfc_train = rfc_gridCV.predict(x_train)   \n",
    "    pred_rfc_valid = rfc_gridCV.predict(x_valid)   \n",
    "    pred_knn_train = knn_gridCV.predict(x_train)   \n",
    "    pred_knn_valid = knn_gridCV.predict(x_valid)\n",
    "    pred_gpc_train = gpc_gridCV.predict(x_train)   \n",
    "    pred_gpc_valid = gpc_gridCV.predict(x_valid)\n",
    "    pred_lda_train = lda_gridCV.predict(x_train)   \n",
    "    pred_lda_valid = lda_gridCV.predict(x_valid)\n",
    "    \n",
    "    # Store best params of each classifier for each fold\n",
    "    kfold_intermediate_results.at['SVC_C', f'{fold_num}'] = svc_gridCV.best_params_['svc__C']\n",
    "    kfold_intermediate_results.at['SVC_gamma', f'{fold_num}'] = svc_gridCV.best_params_['svc__gamma']\n",
    "    kfold_intermediate_results.at['RFC_split', f'{fold_num}'] = rfc_gridCV.best_params_['rfc__min_samples_split']\n",
    "    kfold_intermediate_results.at['RFC_leaf', f'{fold_num}'] = rfc_gridCV.best_params_['rfc__min_samples_leaf']\n",
    "    kfold_intermediate_results.at['KNN_N', f'{fold_num}'] = knn_gridCV.best_params_['knn__n_neighbors']\n",
    "    kfold_intermediate_results.at['GPC_restarts', f'{fold_num}'] = gpc_gridCV.best_params_['gpc__n_restarts_optimizer']\n",
    "    kfold_intermediate_results.at['LDA_tol', f'{fold_num}'] = lda_gridCV.best_params_['lda__tol']\n",
    "   \n",
    "    # Store K-Fold intermedaite results\n",
    "    kfold_intermediate_results.at['SVC_train', f'{fold_num}'] = 1-accuracy_score(y_true=y_train, y_pred=pred_svc_train)\n",
    "    kfold_intermediate_results.at['SVC_valid', f'{fold_num}'] = 1-accuracy_score(y_true=y_valid, y_pred=pred_svc_valid)\n",
    "    kfold_intermediate_results.at['RFC_train', f'{fold_num}'] = 1-accuracy_score(y_true=y_train, y_pred=pred_rfc_train)\n",
    "    kfold_intermediate_results.at['RFC_valid', f'{fold_num}'] = 1-accuracy_score(y_true=y_valid, y_pred=pred_rfc_valid)\n",
    "    kfold_intermediate_results.at['KNN_train', f'{fold_num}'] = 1-accuracy_score(y_true=y_train, y_pred=pred_knn_train)\n",
    "    kfold_intermediate_results.at['KNN_valid', f'{fold_num}'] = 1-accuracy_score(y_true=y_valid, y_pred=pred_knn_valid)\n",
    "    kfold_intermediate_results.at['GPC_train', f'{fold_num}'] = 1-accuracy_score(y_true=y_train, y_pred=pred_gpc_train)\n",
    "    kfold_intermediate_results.at['GPC_valid', f'{fold_num}'] = 1-accuracy_score(y_true=y_valid, y_pred=pred_gpc_valid)    \n",
    "    kfold_intermediate_results.at['LDA_train', f'{fold_num}'] = 1-accuracy_score(y_true=y_train, y_pred=pred_lda_train)\n",
    "    kfold_intermediate_results.at['LDA_valid', f'{fold_num}'] = 1-accuracy_score(y_true=y_valid, y_pred=pred_lda_valid)\n",
    "    \n",
    "# After running all K-Folds get average results for each classifier\n",
    "kfold_intermediate_results['mean'] = kfold_intermediate_results.mean(axis=1)\n",
    "\n",
    "print()\n",
    "print('--- GridSearch Best Parameters ---')\n",
    "print(f'Mean SVC C Parameter: {kfold_intermediate_results[\"mean\"][\"SVC_C\"]}')\n",
    "print(f'Mean SVC gamma Parameter: {kfold_intermediate_results[\"mean\"][\"SVC_gamma\"]}')\n",
    "print(f'Mean RFC min_samples_split Parameter: {kfold_intermediate_results[\"mean\"][\"RFC_split\"]}')\n",
    "print(f'Mean RFC min_samples_leaf Parameter: {kfold_intermediate_results[\"mean\"][\"RFC_leaf\"]}')\n",
    "print(f'Mean KNN N Parameter: {kfold_intermediate_results[\"mean\"][\"RFC_split\"]}')\n",
    "print(f'Mean GPA n_restarts_optimizer Parameter: {kfold_intermediate_results[\"mean\"][\"GPC_restarts\"]}')\n",
    "print(f'Mean LDA tol Parameter: {kfold_intermediate_results[\"mean\"][\"LDA_tol\"]}')\n",
    "print()\n",
    "print('--- K-Fold Cross-Validation Results ---')\n",
    "print(f'SVC Error | Training : {kfold_intermediate_results[\"mean\"][\"SVC_train\"]}')\n",
    "print(f'RFC Error | Training : {kfold_intermediate_results[\"mean\"][\"RFC_train\"]}')\n",
    "print(f'KNN Error | Training : {kfold_intermediate_results[\"mean\"][\"KNN_train\"]}')\n",
    "print(f'GPC Error | Training : {kfold_intermediate_results[\"mean\"][\"GPC_train\"]}')\n",
    "print(f'LDA Error | Training : {kfold_intermediate_results[\"mean\"][\"LDA_train\"]}')\n",
    "print()\n",
    "print(f'SVC Error | Validation : {kfold_intermediate_results[\"mean\"][\"SVC_valid\"]}')\n",
    "print(f'RFC Error | Validation : {kfold_intermediate_results[\"mean\"][\"RFC_valid\"]}')\n",
    "print(f'KNN Error | Validation : {kfold_intermediate_results[\"mean\"][\"KNN_valid\"]}')\n",
    "print(f'GPC Error | Validation : {kfold_intermediate_results[\"mean\"][\"GPC_valid\"]}')\n",
    "print(f'LDA Error | Validation : {kfold_intermediate_results[\"mean\"][\"LDA_valid\"]}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-observer",
   "metadata": {},
   "source": [
    "Considering the validation data the Random Forest Classifier is ahead, but none of the other algorithms is too far behind!\n",
    "Let me now use the best hyperparameters from each K-Fold iteration to build a final version of each model to be tested on the test dataset, so that I can select the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-portsmouth",
   "metadata": {},
   "source": [
    "### 2.3 Comparing Results of the Optimized Classifiers & Selecting the Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "monthly-heart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ MODEL OVERALL ------------------------------\n",
      "SVC Error | Training:  0.009641255605381205\n",
      "RFC Error | Training:  0.00022421524663673864\n",
      "KNN Error | Training:  0.00022421524663673864\n",
      "GPC Error | Training:  0.00022421524663673864\n",
      "LDA Error | Training:  0.00022421524663673864\n",
      "\n",
      "SVC Error | Testing:  0.11834961997828453\n",
      "RFC Error | Testing:  0.053203040173724236\n",
      "KNN Error | Testing:  0.2041259500542888\n",
      "GPC Error | Testing:  0.21172638436482083\n",
      "LDA Error | Testing:  0.21172638436482083\n"
     ]
    }
   ],
   "source": [
    "# Dataframe to store results\n",
    "summary = pd.DataFrame()\n",
    "\n",
    "# Create new classifiers using the average of the best parameters in each k-fold\n",
    "svc_kfold = SVC(kernel=\"rbf\", decision_function_shape='ovr',\n",
    "                C=kfold_intermediate_results.at['SVC_C', 'mean'],\n",
    "                gamma=kfold_intermediate_results.at['SVC_gamma', 'mean'])\n",
    "\n",
    "rfc_kfold = RandomForestClassifier(n_estimators=100, criterion='gini', n_jobs=-1,\n",
    "                                   min_samples_split=round(kfold_intermediate_results.at['RFC_split', 'mean']),\n",
    "                                   min_samples_leaf=round(kfold_intermediate_results.at['RFC_leaf', 'mean']))\n",
    "\n",
    "knn_kfold = KNeighborsClassifier(metric='minkowski', leaf_size=30, weights='distance', n_jobs=-1,\n",
    "                                 n_neighbors=round(kfold_intermediate_results.at['KNN_N', 'mean']))\n",
    "\n",
    "gpc_kfold = GaussianProcessClassifier(optimizer='fmin_l_bfgs_b', max_iter_predict=100, n_jobs=-1,\n",
    "                                      n_restarts_optimizer=round(kfold_intermediate_results[\"mean\"][\"GPC_restarts\"]))\n",
    "                                       \n",
    "lda_kfold = LinearDiscriminantAnalysis(solver='svd',\n",
    "                                       tol=kfold_intermediate_results.at['LDA_tol', 'mean'])\n",
    "\n",
    "\n",
    "# Get X's and Y's - This time using the full datasets for trainin and testing\n",
    "x_train, y_train = smote.fit_sample(df_train.iloc[:,:-1], df_train.iloc[:,-1])\n",
    "x_test = df_test.iloc[:, :-1].copy()\n",
    "y_test = df_test.iloc[:, -1].copy()\n",
    "\n",
    "# Fit using the optimized model created with the mean hyperparameters from K-Fold cross-validation\n",
    "svc_kfold.fit(x_train, y_train)\n",
    "rfc_kfold.fit(x_train, y_train)\n",
    "knn_kfold.fit(x_train, y_train)\n",
    "gpc_kfold.fit(x_train, y_train)\n",
    "lda_kfold.fit(x_train, y_train)                                     \n",
    "                                       \n",
    "# Predict\n",
    "pred_svc_train = svc_kfold.predict(x_train)\n",
    "pred_svc_test = svc_kfold.predict(x_test)\n",
    "pred_rfc_train = rfc_kfold.predict(x_train)\n",
    "pred_rfc_test = rfc_kfold.predict(x_test)\n",
    "pred_knn_train = knn_kfold.predict(x_train)\n",
    "pred_knn_test = knn_kfold.predict(x_test)\n",
    "pred_gpc_train = gpc_kfold.predict(x_train)\n",
    "pred_gpc_test = gpc_kfold.predict(x_test)\n",
    "pred_lda_train = gpc_kfold.predict(x_train)\n",
    "pred_lda_test = gpc_kfold.predict(x_test)\n",
    "                                       \n",
    "# Model Error\n",
    "summary.at['train', f'SVC'] = 1-accuracy_score(y_true=y_train, y_pred=pred_svc_train)\n",
    "summary.at['test', f'SVC'] = 1-accuracy_score(y_true=y_test, y_pred=pred_svc_test)\n",
    "summary.at['train', f'RFC'] = 1-accuracy_score(y_true=y_train, y_pred=pred_rfc_train)\n",
    "summary.at['test', f'RFC'] = 1-accuracy_score(y_true=y_test, y_pred=pred_rfc_test)\n",
    "summary.at['train', f'KNN'] = 1-accuracy_score(y_true=y_train, y_pred=pred_knn_train)\n",
    "summary.at['test', f'KNN'] = 1-accuracy_score(y_true=y_test, y_pred=pred_knn_test)\n",
    "summary.at['train', f'GPC'] = 1-accuracy_score(y_true=y_train, y_pred=pred_gpc_train)\n",
    "summary.at['test', f'GPC'] = 1-accuracy_score(y_true=y_test, y_pred=pred_gpc_test)\n",
    "summary.at['train', f'LDA'] = 1-accuracy_score(y_true=y_train, y_pred=pred_lda_train)\n",
    "summary.at['test', f'LDA'] = 1-accuracy_score(y_true=y_test, y_pred=pred_lda_test)\n",
    "                                        \n",
    "# Print model results for optimized classifiers model\n",
    "print(f'------------------------------ MODEL OVERALL ------------------------------') \n",
    "print('SVC Error | Training: ', summary.at['train', f'SVC'])\n",
    "print('RFC Error | Training: ', summary.at['train', f'RFC'])                                       \n",
    "print('KNN Error | Training: ', summary.at['train', f'KNN'])\n",
    "print('GPC Error | Training: ', summary.at['train', f'GPC'])                                       \n",
    "print('LDA Error | Training: ', summary.at['train', f'LDA'])                                     \n",
    "print()                                       \n",
    "print('SVC Error | Testing: ', summary.at['test', f'SVC'])\n",
    "print('RFC Error | Testing: ', summary.at['test', f'RFC'])\n",
    "print('KNN Error | Testing: ', summary.at['test', f'KNN'])\n",
    "print('GPC Error | Testing: ', summary.at['test', f'GPC'])\n",
    "print('LDA Error | Testing: ', summary.at['test', f'LDA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "least-louisville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVC</th>\n",
       "      <th>RFC</th>\n",
       "      <th>KNN</th>\n",
       "      <th>gpc</th>\n",
       "      <th>LDA</th>\n",
       "      <th>GPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.009641</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.118350</td>\n",
       "      <td>0.053203</td>\n",
       "      <td>0.204126</td>\n",
       "      <td>0.206298</td>\n",
       "      <td>0.211726</td>\n",
       "      <td>0.211726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SVC       RFC       KNN       gpc       LDA       GPC\n",
       "train  0.009641  0.000224  0.000224  0.000224  0.000224  0.000224\n",
       "test   0.118350  0.053203  0.204126  0.206298  0.211726  0.211726"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View results in the dataframe\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-possible",
   "metadata": {},
   "source": [
    "Among the optimized models there were many ties in the training set, but when looking at the testing set, the Random Forecast Classifier is the clear winner!\n",
    "\n",
    "But before I move ahead to calculating the performance metrics for our winning algorithm, let's introduce one final challenger: TPOT's AutoML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-alliance",
   "metadata": {},
   "source": [
    "### Bonus: AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-graphic",
   "metadata": {},
   "source": [
    "Attempting to improve on the performance of the best classifier by using TPOT's AutoML tool to search for an ideal classifier pipeline.\n",
    "\n",
    "TPOT AutoML Documentation: http://epistasislab.github.io/tpot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "polyphonic-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and Y\n",
    "x_train = df_train.iloc[:,:-1]\n",
    "y_train= df_train.iloc[:,-1]\n",
    "x_test = df_test.iloc[:,:-1]\n",
    "y_test= df_test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "little-force",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 0.11.6.post3 of tpot is outdated. Version 0.11.7 was released Wednesday January 06, 2021.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/120 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9535326086956522\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.9535326086956522\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.9535326086956522\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.9535326086956522\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.9546195652173914\n",
      "\n",
      "Best pipeline: GradientBoostingClassifier(input_matrix, learning_rate=0.5, max_depth=10, max_features=0.7000000000000001, min_samples_leaf=18, min_samples_split=7, n_estimators=100, subsample=0.8500000000000001)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(generations=5, n_jobs=-1, population_size=20, verbosity=2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Instantiate and run the AutoML classifier\n",
    "AutoML = TPOTClassifier(generations=5, population_size=20, cv=5, verbosity=2, n_jobs=-1)\n",
    "AutoML.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "gothic-purpose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.5, max_depth=10,\n",
       "                           max_features=0.7000000000000001, min_samples_leaf=18,\n",
       "                           min_samples_split=7, subsample=0.8500000000000001)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And the best model is:\n",
    "pipeline_optimizer.fitted_pipeline_.steps[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "hired-track",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML Error | Training:  0.0005434782608695343\n",
      "AutoML Error | Testing:  0.0456026058631922\n"
     ]
    }
   ],
   "source": [
    "# Check performance\n",
    "print(\"AutoML Error | Training: \", 1-AutoML.score(x_train, y_train))\n",
    "print(\"AutoML Error | Testing: \", 1-AutoML.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-beginning",
   "metadata": {},
   "source": [
    "Looks like TPOT proved no match for our Random Forest Classifier, so let's move ahead with extracting performance metrics for our champion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-investigator",
   "metadata": {},
   "source": [
    "## 3. Evaluating the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-somerset",
   "metadata": {},
   "source": [
    "Now the the best model has been identified, rerun a K-Fold cross-validation without using SMOTE, so that more representative FPR, FNR and Error values can be obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "mighty-bloom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Fold: 1\n",
      "Working on Fold: 2\n",
      "Working on Fold: 3\n",
      "Working on Fold: 4\n",
      "Working on Fold: 5\n"
     ]
    }
   ],
   "source": [
    "# Now let's run a K-Fold cross-validation with the winner model and see how it performs over each fold\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "scores_train, scores_valid, scores_test = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "for fold_num, (idx_train, idx_valid) in enumerate(kf.split(df_train), 1):\n",
    "    \n",
    "    # Print current label and fold\n",
    "    print(f'Working on Fold: {fold_num}')\n",
    "\n",
    "    # Select all folds to be smoted except for the validation fold\n",
    "    x_train = df_train.iloc[idx_train,:-1].copy() \n",
    "    y_train = df_train.iloc[idx_train,-1].copy() \n",
    "    x_valid = df_train.iloc[idx_valid,:-1].copy() \n",
    "    y_valid = df_train.iloc[idx_valid,-1].copy() \n",
    "    x_test = df_test.iloc[:, :-1].copy()\n",
    "    y_test = df_test.iloc[:, -1].copy()\n",
    "    \n",
    "    # Fit a Random Forest Classifier using the best parameters\n",
    "    winner_model = RandomForestClassifier(n_estimators=100, criterion='gini', n_jobs=-1,\n",
    "                                   min_samples_split=round(kfold_intermediate_results.at['RFC_split', 'mean']),\n",
    "                                   min_samples_leaf=round(kfold_intermediate_results.at['RFC_leaf', 'mean']))\n",
    "    \n",
    "    winner_model.fit(x_train, y_train)\n",
    "    \n",
    "    # Predict on the train and validation folds to calculate metrics (with the winnier rfc_kfold model)\n",
    "    pred_train = winner_model.predict(x_train)   \n",
    "    pred_valid = winner_model.predict(x_valid)\n",
    "    pred_test = winner_model.predict(x_test)\n",
    "    \n",
    "    # Train dataset metrics\n",
    "    scores_train.at[f'{fold_num}', 'Error'] = 1-accuracy_score(y_true=y_train, y_pred=pred_train)\n",
    "    cm_train = confusion_matrix(y_train, pred_train)\n",
    "    TN, FP, FN, TP = cm_train.ravel()\n",
    "    scores_train.at[f'{fold_num}', 'FPR'] = FP/(FP+TN)\n",
    "    scores_train.at[f'{fold_num}', 'FNR'] = FN/(TP+FN)\n",
    "    \n",
    "    # Valid dataset metrics\n",
    "    scores_valid.at[f'{fold_num}', 'Error'] = 1-accuracy_score(y_true=y_valid, y_pred=pred_valid)\n",
    "    cm_valid = confusion_matrix(y_valid, pred_valid)\n",
    "    TN, FP, FN, TP = cm_valid.ravel()\n",
    "    scores_valid.at[f'{fold_num}', 'FPR'] = FP/(FP+TN)\n",
    "    scores_valid.at[f'{fold_num}', 'FNR'] = FN/(TP+FN)\n",
    "    \n",
    "    # Test dataset metrics\n",
    "    scores_test.at[f'{fold_num}', 'Error'] = 1-accuracy_score(y_true=y_test, y_pred=pred_test)\n",
    "    cm_test = confusion_matrix(y_test, pred_test)\n",
    "    TN, FP, FN, TP = cm_test.ravel()\n",
    "    scores_test.at[f'{fold_num}', 'FPR'] = FP/(FP+TN)\n",
    "    scores_test.at[f'{fold_num}', 'FNR'] = FN/(TP+FN)\n",
    "\n",
    "# Get mean scores over all K-folds\n",
    "scores_train.at['mean', 'Error'] = scores_train['Error'].mean()\n",
    "scores_train.at['mean', 'FPR'] = scores_train['FPR'].mean()\n",
    "scores_train.at['mean', 'FNR'] = scores_train['FNR'].mean()\n",
    "scores_valid.at['mean', 'Error'] = scores_valid['Error'].mean()\n",
    "scores_valid.at['mean', 'FPR'] = scores_valid['FPR'].mean()\n",
    "scores_valid.at['mean', 'FNR'] = scores_valid['FNR'].mean()\n",
    "scores_test.at['mean', 'Error'] = scores_test['Error'].mean()\n",
    "scores_test.at['mean', 'FPR'] = scores_test['FPR'].mean()\n",
    "scores_test.at['mean', 'FNR'] = scores_test['FNR'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "continent-teddy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Error       FPR       FNR\n",
       "1     0.000000  0.000000  0.000000\n",
       "2     0.000340  0.000000  0.000860\n",
       "3     0.000679  0.000000  0.001715\n",
       "4     0.000679  0.000561  0.000862\n",
       "5     0.000340  0.000000  0.000871\n",
       "mean  0.000408  0.000112  0.000862"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "beautiful-juvenile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057065</td>\n",
       "      <td>0.048998</td>\n",
       "      <td>0.069686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050272</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>0.090592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039402</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>0.059859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044837</td>\n",
       "      <td>0.024664</td>\n",
       "      <td>0.075862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.052989</td>\n",
       "      <td>0.034562</td>\n",
       "      <td>0.079470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.048913</td>\n",
       "      <td>0.031854</td>\n",
       "      <td>0.075094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Error       FPR       FNR\n",
       "1     0.057065  0.048998  0.069686\n",
       "2     0.050272  0.024499  0.090592\n",
       "3     0.039402  0.026549  0.059859\n",
       "4     0.044837  0.024664  0.075862\n",
       "5     0.052989  0.034562  0.079470\n",
       "mean  0.048913  0.031854  0.075094"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "artificial-fetish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052117</td>\n",
       "      <td>0.039427</td>\n",
       "      <td>0.071625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048860</td>\n",
       "      <td>0.034050</td>\n",
       "      <td>0.071625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051031</td>\n",
       "      <td>0.034050</td>\n",
       "      <td>0.077135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048860</td>\n",
       "      <td>0.030466</td>\n",
       "      <td>0.077135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.052117</td>\n",
       "      <td>0.030466</td>\n",
       "      <td>0.085399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.050597</td>\n",
       "      <td>0.033692</td>\n",
       "      <td>0.076584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Error       FPR       FNR\n",
       "1     0.052117  0.039427  0.071625\n",
       "2     0.048860  0.034050  0.071625\n",
       "3     0.051031  0.034050  0.077135\n",
       "4     0.048860  0.030466  0.077135\n",
       "5     0.052117  0.030466  0.085399\n",
       "mean  0.050597  0.033692  0.076584"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-brooks",
   "metadata": {},
   "source": [
    "Note: It is possible to obtain all the metrics (error, FPR, FNR) while comparing all optimized models.\n",
    "\n",
    "I've chosen to re-train the winning model and calculate the metrics only for that model for the sake of clarity, as I believe this apporach makes the step-by-step of the pipeline I've implemented clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "formed-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix\n",
    "def show_confusion_matrix(confusion_matrix):\n",
    "    hmap = sns.heatmap(confusion_matrix, annot = True, fmt = \"d\", cmap = \"Blues\", square=True)\n",
    "    hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation = 0, ha = \"right\")\n",
    "    hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation = 0, ha = \"right\")\n",
    "    plt.title('Confusion Matrix', pad=20, fontweight='bold', fontsize=15)\n",
    "    plt.ylabel('True Class')\n",
    "    plt.xlabel('Predicted Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "statutory-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot ROC-AUC Curve\n",
    "def show_roc_curve(roc_curve):\n",
    "    auc_score = auc(roc_curve[0], roc_curve[1])\n",
    "    plt.axis('square')\n",
    "    plt.plot(roc_curve[0], roc_curve[1], color='tomato', lw=3, label='AUC: ' + str(auc_score))\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1.5)\n",
    "    plt.xlim([-0.01, 1.01])\n",
    "    plt.ylim([-0.01, 1.01])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve', pad=20, fontweight='bold', fontsize=15)\n",
    "    legend = plt.legend('AUC Score')\n",
    "    legend._legend_box.align = \"right\"\n",
    "    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "functional-antigua",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'seaborn' has no attribute 'heatmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-80a4afbd74d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshow_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-130-7cae5447b8e5>\u001b[0m in \u001b[0;36mshow_confusion_matrix\u001b[1;34m(confusion_matrix)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Function to plot confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mshow_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mhmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Blues\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquare\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mhmap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhmap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"right\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mhmap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhmap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"right\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'seaborn' has no attribute 'heatmap'"
     ]
    }
   ],
   "source": [
    "show_confusion_matrix(cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-findings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-observer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "partial-audience",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'seaborn' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-f656a9a2faef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'seaborn' has no attribute '__version__'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-winter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
